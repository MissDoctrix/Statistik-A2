---
title: "abstract"
author:
  - "Carys Artemis Lamm"
  - "Lara Senger"
  - "Mino Wittemann"
date: today
date-format: "D. MMMM YYYY"
format:
  pdf:
    papersize: a4
    fontsize: 12pt
    number-sections: true
    fig-cap-location: top
    fig-numbering: true
    tbl-numbering: true
    code-fold: true
  html:
    fontsize: 12pt
    number-sections: true
    fig-numbering: true
    tbl-numbering: true
    code-fold: true
lang: de
bibliography: literatur.bib
csl: apa7.csl
---

**GitHub Repository:** <https://github.com/MissDoctrix/Statistik-A2.git>\
**Für die Abgabe aktueller GitHub Hash:** 499f4c25c5c0206799208c89664014b3e7679dde

## Einleitung

## Literaturübersicht

Es stehen zwei Fragen im Fokus der Literaturrecherche: Erstens, was sind Nutzendenanforderungen an künstliche Intelligenz (im Folgenden mit KI abgekürzt) als Werkzeug zur Unterstützung bei der Detektion von Misinformation auf Social Media? Zweitens, wie gehen Personen in diesem Kontext mit unterschiedlichen Feedback-Arten um?

Einen ersten Einblick in den wissenschaftlichen Forschungsstand und in die Thematik bieten @szczepanski_new_2021. Ihre Arbeit präsentiert eine Erklärungsmethode, mit der deep learning Fake‑News-Modelle nachvollziehbarer werden, indem es die Textstellen hervorhebt, die das Urteil am stärksten beeinflussen. Diese Untersuchung bietet dabei einen Ansatz für die Frage, wie die Ausgabe von KI Werkzeuge gestaltet werden kann, allerdings beinhaltet die Arbeit keine Untersuchung mit verschiedenen Nutzergruppen und ihrem Feedback.

Ähnlichen Einblick bietet @reis_explainable_2019, deren Arbeit ebenfalls die Erklärbarkeit von KI Modellen zur Fake-News-Detektion fokussiert. Durch Verwendung unterschiedlichen Daten versucht das Modell eine ganzheitliche Bewertung zu erreichen und diese nachvollziehbar für Nutzende zu machen, indem das System hervorhebt, welche Merkmale am meisten zu einer Entscheidung betragen. Allerdings liegt auch hier keine direkte Nutzerforschung vor, die Bedürfnisse der Nutzenden wurden aus Literatur extrahiert und analysiert, jedoch nicht nicht durch eine testende Studie überprüft.

Eine andere Arbeit von @shu_defend_2019 evaluiert in einer Nutzendenstudie, wie gut Erklärungen und Kommentare bezüglich der Entscheidung einer KI, was ob Nachrichteninhalte Fake News sind, verstanden werden. Dies sind wichtige Orientierungspunkte für die Forschungsfragen. Jedoch untersucht die Arbeit nicht weitergehend, wie unterschiedliche Feedbackformen von den Nutzenden bewertet werden und wie sehr ihnen Vertrauen entgegen gebracht wird.

Die drei genannten Forschungsarbeiten bieten einen ersten Ansatz, sich mit dem Themenfeld vertraut zu machen. Jedoch müssen mehr wissenschaftliche Veröffentlichungen mit dem Schwerpunkt auf Wahrnehmung und Beurteilung unterschiedlicher Feedbacksysteme durch die Nutzenden herangezogen werden, die zudem den Fokus aus Nutzendentests legen und diese Untersuchungen vergleichen. Ebenso sind mehr Arbeiten zu suchen, die empirisch untersuchen, welche Anforderungen durch die Nutzenden gestellt werden und ob sich diese in bestehenden Modellen bereits wiederfinden.

Anknüpfend an die Literatur liegt unser Fokus auf der Analyse konzeptioneller und gestalterischer Anforderungen, die Nutzende an eine KI-Anwendung stellen.

## Methode

### Qualitative Methode

Um zu untersuchen, welche Anforderungen Nutzende an eine KI-Anwendung zur Erkennung von Misinformation auf Social Media stellen, wurde die qualitative Forschungsmethode des leitfadengestützten Interviews gewählt. Personeninterviews ermöglichen es, Themen aus Sicht der Befragten zu identifizieren und diese in weiteren Analyseschritten zu vertiefen. Durch offen formulierte Fragen können individuelle Perspektiven, relevante Erfahrungen und subjektive Einschätzungen eingebracht werden, die bei standardisierten Frageformaten möglicherweise unberücksichtigt bleiben. Anstatt Themen vorzugeben, erlaubt die Interviewmethode, relevante Inhalte direkt aus den Antworten der Teilnehmenden abzuleiten und für die Bearbeitung der Forschungsfrage nutzbar zu machen.

Für die Stichprobe wurden gezielt junge Erwachsene ausgewählt, die regelmäßig soziale Medien nutzen und bereits Erfahrungen mit künstlicher Intelligenz gesammelt haben. Die Interviews orientierten sich an einem thematischen Leitfaden und umfassten Fragen zu Vorerfahrungen zu KI, Nutzungsverhalten bezüglich Social Media sowie Erwartungen an eine KI-Anwendung, die über erkannte Misinformation informiert. Die Gespräche wurden über eine mobile Applikation lokal auf dem Gerät aufgezeichnet. Die Transkripte wurden zunächst mithilfe der Software @whispertranscribe2025 erstellt und anschließend von einer zweiten Person korrigiert und formal überarbeitet.

Die Auswertung erfolgte anhand der sechsstufigen thematischen Analyse. Zur Strukturierung wurde im Programm Excel von @microsoft_excel_2024 eine Tabelle angelegt, in der Codes thematisch geordnet, zu Kategorien zusammengeführt und mit exemplarischen Zitaten aus den Interviews verknüpft wurden. Die Tabelle diente zugleich als Arbeitsgrundlage zur Überprüfung, Anpassung und finalen Formulierung der Themen und Definitionen. In mehreren Korrekturschleifen wurden diese überarbeitet und zu einem gemeinsamen Analyseergebnis verdichtet.

### Quantitative Methode

Für die Rekrutierung der Teilnehmenden wurden insgesamt sechs Einschluss- bzw. Ausschlusskriterien definiert. Zur Sicherstellung der rechtlichen Einwilligung in die Verarbeitung personenbezogener Daten haben wir ein Mindestalter von 18 Jahren festgelegt. Eine obere Altersgrenze haben wir nicht gesetzt, um eine möglichst vielfältige Stichprobe zu ermöglichen. Ausgeschlossen wurden Personen, die aktuell an der Veranstaltung Statistik und Methoden der Nutzerforschung teilnehmen, da ihnen durch die Lehrveranstaltung potenziell Vorwissen zum Studiendesign vorliegt, sie somit nicht unvoreingenommen die Befragung bearbeiten können.Die Befragung wurde ausschließlich in deutscher Sprache durchgeführt. Entsprechend wurden nur deutschsprachige Personen als Teilnehmende gesucht, um Verständnisschwierigkeiten vermeiden. Darüber hinaus war für die Teilnahme der Zugriff Tablet, Laptop oder PC mit aktuellem Browser erforderlich, da die Online-Befragung ausschließlich für Desktop-Oberflächen konzipiert wurde und eine kompatible Anzeigeumgebung benötigt.Ein weiteres Einschlusskriterium war die zumindest gelegentliche Nutzung von sozialen Medien, da die Untersuchung auf Erfahrungen und Einschätzungen im Kontext von Social Media Bezug nehmen. Vorerfahrungen mit KI-Systemen haben wir hingegen bewusst nicht vorausgesetzt, da die KI unterstützte Anwendung kein Vorwissen benötigt. Dadurch sollte ein bereiteres Bild hinsichtlich der unterschiedlichen Technikaffinität und des Vorwissens ermöglicht werden. Die Befragung wurde im Zeitraum vom Samstag, 24. Mai 2025, bis zum Montag, 2. Juni 2025 durchgeführt. Die Rekrutierung der Teilnehmenden erfolgte sowohl mündlich im persönlichen Umfeld als auch durch die Verbreitung mittels eines Rekrutierungstextes. Es wurden so viele Teilnehmende wie möglich aus dem näheren Bekanntenumfeld gesucht mit einer Mindestgrenze von 15 Teilnehmenden. Die Befragung wurde von den Teilnehmenden eigenständig online bearbeitet.

Die Studie folgte einem Mixed-Design, bestehend aus einem between-subjects- sowie einem within-subjects-Anteil. Alle Teilnehmenden führten zunächst eine Bewertung von Social Media Posts ohne Unterstützung durch KI durch (within-subjects-Design), gefolgt von einer Bewertung mit KI-Unterstützung. Die Teilnehmenden wurden randomisiert einer von zwei Varianten eines KI-Systems zugewiesen (between-subjects-Design). Die eine Häfte bewertete eine evaluierende, die andere eine empfehlende KI-Variante.

------------------------------------------------------------------------

![Ablauf der quantitativen Studie](Diagram1.png){#fig-ablauf-studie width="100%"}

Die Datenerhebung bestand aus insgesamt fünf Abschnitten (wie in @fig-ablauf-studie vollständig dargestellt): einem Pre-Test, einer Baseline-Phase, einem Post-Baseline-Fragebogen, dem Test der Anwendung und einem abschleißenden Post-Test-Fragebogen. Im Pre-Test wurden grundlegende demografische Daten erfasst, darunter das Alter der Teilnehmenden (metrisch), das Geschlecht (nominalskaliert: männlich, weiblich, divers) sowie der Bildungsstand (ordinalskaliert mit mehreren Bildungsstufen). Zusätzlich wurden Angaben zur Technikaffinität (metrisch), zur Nutzung sozialer Medien (teils ordinal und teils nominal) sowie zum Vorwissen über KI (metrisch) erfasst. Im Hauptteil der Studie mussten die Teilnehmenden 20 Social-Media-Beiträge bewerten, die potentiell Falschinformationen enthielten. Die Beiträge waren in zwei Phasen aufgeteilt: In der ersten Phase (Baseline) wurden zehn Beiträge ohne Unterstützung durch ein KI-System bewertet. In der zweiten Phase (Test der Anwendung) erfolgte die Bewertung von zehn weiteren Beiträgen, hier mit Unterstützung durch eines von zwei KI-Systemen: entweder ein evaluatives System, das eine eigene Einschätzung abgibt, oder ein empfehlendes System, das eine Handlungsempfehlung formuliert. Die Zuordnung der KI-Systeme erfolgte zwischen den Teilnehmenden randomisiert. Zu jedem Beitrag sollten die Teilnehmenden einschätzen, ob es sich um Falschinformationen handelt (ja/nein). Diese Einschätzung wurde binär erfasst (nominalskaliert). Parallel wurde erfasst, unter welcher Systembedingung der jeweilige Beitrag präsentiert wurde: entweder ohne Assistenz (Baseline), mit einer evaluativen Entscheidungshilfe oder mit einer direkten Empfehlung. Nach jeder der beiden Bewertungsphasenwurde ein Post-Test durchgeführt, in dem die subjektiv empfundene mentale Belastung abgefragt wurde. Dafür kam hier eine Skala zum Einsatz, die sich an der DLR-Workload-Skala orientiert. Diese Skala misst fünf Bereiche der mentalen Beanspruchung: Informationsaufnahme, Wissensabruf, Entscheidungsfindung, motorische Beanspruchung und zeitlicher Druck. Jeder Bereich wurde einzeln auf einer visuellen Analogskala von 0 (sehr stark unterbeansprucht) bis 200 (sehr stark überbeansprucht) bewertet, wobei 100 als optimaler Wert gilt. Die Teilnehmenden konnten somit sehr differenziert angeben, wie belastend sie die Aufgaben empfanden. Die DLR-Skala gilt als ökonomisch, da sie trotz weniger Fragen eine differenzierte Erfassung ermöglicht. Die binäre Entscheidung bei den Beiträgen (ja/nein) ist angemessen für unser Ziel, um herauszufinden, wie sicher und richtig Teilnehmende Falschinformationen erkennen. Insgesamt liefert der Studiendesign sowohl objektive Daten (Entscheidung pro Beitrag), als auch subjektive Einschätzungen (über die Belastung). Damit lässt sich analysieren, ob und wie die KI-Systeme einen Einfluss auf das Erkennen von Desinformation haben.

Zur Analyse der erhobenen Daten sind zwei zentrale statistische Verfahren geplant: Ein t-Test für unabhängige Stichproben sowie eine Korrelationsanalyse nach Pearson. Dadurch können sowohl Gruppenunterschiede als auch die Zusammenhänge zwischen ausgewählten Variablen untersucht werden. Zunächst wird zur Untersuchung von Gruppenunterschieden ein t-Test für unabhängige Stichproben eingesetzt. Dieser Test prüft, ob sich die mittlere subjektive Belastung (erhoben mit der DLR Workload-Skala) in Abhängigkeit von der Art der KI-Unterstützung (evaluativ vs. empfehlend) signifikant unterscheidet. Die Belastung wird dabei als metrisch skalierte Variable behandelt, da sie auf einer visuellen Analogskala von 0 bis 200 erhoben wurde. Die Gruppenzuordnung (Art der KI) ist nominalskaliert, weshalb sich der t-Test als geeignete Methode zur Prüfung dieser Hypothese anbietet. Das Ziel dieser Analyse ist es herauszufinden, ob eine bestimmte Form der KI-Assistenz kognitiv entlastender wirkt als die andere, was für die Gestaltung zukünftiger Systeme relevant sein könnte. Ergänzend dazu wird eine Korrelation nach Pearson durchgeführt, um mögliche Zusammenhänge zwischen der subjektive empfundenen Belastung und dem Vertrauen in das KI-System zu untersuchen. Das Vertrauen wurde im Post-Test mit Hilfe mehreren Aussagen auf einer metrisch interpretierten Likert-Skala erfasst. Da beide Variablen (subjektive Belastung und Vertrauen) als intervallskaliert gelten, ist der Pearson-Korrelationskoeffizient eine geeignete Methode zur Analyse. Diese Analyse soll zeigen, ob beispielsweise eine höhere Belastung mit einem niedrigeren Vertrauen in das System einhergeht. Für beide Analysen wird ein Signifikanzniveau von α = 0,05 festgelegt.

## Ergebnisse

### Qualitative Ergebnisse

Insgesamt wurden zwei leitfadengestützte Interviews durchgeführt und analysiert. Die interviewten Personen sind junge Erwachsene, die soziale Medien aktiv und regelmäßig in ihrem Alltag nutzen. Zudem verfügen sie über Vorkenntnisse im Bereich künstlicher Intelligenz, insbesondere sind ihnen Large Language Models wie ChatGPT bekannt und sie haben diese bereits genutzt. Die Stichprobe weist somit relevantes Vorwissen hinsichtlich der Funktionsweise sowie der Interaktionsmöglichkeiten mit KI-Systemen auf.

Im Rahmen der Interviews konnten mehrere thematische Schwerpunkte identifiziert werden, die von den Befragten als zentrale Anforderungen an eine KI-Anwendung zur Erkennung von Misinformation auf Social Media formuliert wurden.

| Name | Definition | Textstelle |
|:-----------------------|:-----------------------|:-----------------------|
| Barrierefreiheit | Die Barrierefreiheit beschreibt den Anspruch, dass die Gestaltung der Detektion allen Menschen eine gleichberechtigte und selbstständige Nutzung ermöglicht, unabhängig von individuellen Einschränkungen. | „Also, es muss auf jeden Fall einfach zu bedienen sein \[…\]“ (TN_1, Zeile 75). |
| Verfügbarkeit | Unter dem Kriterium der Verfügbarkeit wird verstanden, dass die KI-Anwendung allen Nutzer\*innen jederzeit und unter gleichen Bedingungen zugänglich ist. | „Also, es muss auf jeden Fall \[…\] für jeden gleich verfügbar sein“ (TN_1, Zeile 75). |
| erfassbare Aufbereitung | Die erfassbare Aufbereitung beschreibt den Anspruch, Informationen visuell so zu gestalten, dass sie schnell, klar und inhaltlich korrekt wahrgenommen und verstanden werden können. | „Und genau, mit einfach kommt natürlich auch sprachlich, dass man es versteht und hatte ich gesagt, dass es schnell sein soll, also dass man sehr schnell versteht, was das Ergebnis von der KI ist. Also wenn das jetzt das einschätzt, dass es praktisch am Anfang direkt einmal sagt, das ist richtig, oder das ist falsch, \[...\]“ (TN_1, Zeile 83 - 86). |
| Einsehbarkeit der Quellen | Die Einsehbarkeit der Quellen beschreibt den Anspruch, dass alle verwendeten Informationsquellen klar benannt, zugänglich und auf ihre Richtigkeit überprüfbar sind. | „Das Einzige, was ich vielleicht finde, ist, dass man die Anforderungen an Quellen oder so was noch hinzufügen könnte, dass man halt sagt, ja, woher hast du das oder wie bist du darauf gekommen?“ (TN_1, Zeile 123 - 125) |
| Beständigkeit der Detektionsergebnisse | Unter Beständigkeit der Detektionsergebnisse wird verstanden, dass die Ergebnisse der Misinformations-Detektion konsistent und unabhängig von der Interaktion mit dem User bleiben. | „Und deswegen finde ich es glaube ich eigentlich besser, wenn man wirklich nur die Einschätzung an sich hat, die dann halt feststeht. Und nicht so, weil, also ich habe das Gefühl, dass man sonst mit der KI ins Diskutieren kommt“ (TN_1, Zeile 120 - 122). |
| personenunabhängige Detektion | Die personenunabhängige Detektion beschreibt den Anspruch, dass die Erkennung von Desinformation ohne Einbezug personenbezogene Daten erfolgt. | „Naja, es dürfte halt nicht auf die Leute zugeschnitten sein im Idealfall \[…\]“ (TN_2, Zeile 56). |
| politischen Unabhängigkeit des KI-Tools | Unter politischer Unabhängigkeit wird der Anspruch verstanden, dass die Detektionsanwendung frei von parteipolitischen Einflüssen agiert und ausschließlich auf Grundlage neutraler, objektiver Kriterien Inhalte auf Desinformation prüft und bewertet. | „Es müsste halt sehr unabhängig programmiert sein, dass keine Lobbys oder so damit entwickeln, die halt vielleicht extra falsche Formationen verstreuen wollen“ (TN_2, Zeile 57 - 59). |

: Analyseergebnisse der Interviews {#tbl-analyse}

Wie Table 1 zu entnehmen ist, konnten sieben zentrale Anforderungsbereiche identifiziert werden. So wird der Anspruch formuliert, dass die Gestaltung der KI-Anwendung allen Menschen eine gleichberechtigte und selbstständige Nutzung ermöglichen soll (TN_1, Zeile 75). Ebenso wird auf eine gleichberechtigte Verfügbarkeit Wert gelegt, sodass die Anwendung allen Nutzenden jederzeit und unter gleichen Bedingungen zugänglich ist (TN_1, Zeile 75). Darüber hinaus wird eine visuell-textliche Darstellungsweise gewünscht, die eine schnelle, klare und inhaltlich korrekte Wahrnehmung und Verständlichkeit der bereitgestellten Informationen ermöglicht (TN_1, Zeile 83–86). Dieses Kriterium ist vom Anspruch der Barrierefreiheit abzugrenzen, da es nicht auf die allgemeine Zugänglichkeit der Anwendung, sondern auf die konkrete Darstellung der Inhalte und ihre Erfassung abzielt. Im Zentrum steht hierbei das Ergebnis der KI-Anwendung, das die Nutzenden darüber informiert, ob es sich bei einem Inhalt um Misinformation handelt oder nicht. Zusätzlich soll eine vertiefende Auseinandersetzung mit den zugrunde liegenden Quellen möglich sein, die eine freiwillige Erweiterung der KI-Rückmeldung darstellt (TN_1, Zeile 123–125). Zwar wird die Möglichkeit für Rückfragen zum Verständnis gewünscht (TN_1, Zeile 142), darüber hinausgehende Interaktionen mit der KI-Anwendung werden jedoch abgelehnt. Gefordert wird, dass das Detektionsergebnis unabhängig von weiterer User-Interaktion bleibt und keine dialogische Auseinandersetzung mit der Anwendung möglich ist (TN_1, Zeile 120 - 122). Diese Forderung basiert auf der Erfahrung, dass Chatbots durch Nutzende beeinflussbar sind und dadurch das Ergebnis der Detektion verändert werden könnte. Die geforderte Unabhängigkeit bezieht sich weiterhin auch auf die zugrunde liegenden Daten der KI. Es soll vermieden werden, dass personenbezogene Informationen des Users in die Bewertung einfließen, etwa zur Anpassung an Sprachstil oder politische Haltung (TN_2, Zeile 56). Die Anwendung soll als neutrale Instanz konzipiert sein, unabhängig auch von möglichen Interessen staatlicher oder unternehmerischer Akteure (TN_2, Zeile 57–59). Folglich wird gefordert, dass die Anwendung frei von parteipolitischen Einflüssen agiert und ausschließlich auf Grundlage neutraler, objektiver Kriterien Inhalte auf Desinformation prüft und bewertet. Diese Bewertung soll visuell-textlich für alle Nutzenden schnell und verständlich erfassbar sein. Es soll die Möglichkeit geben, die Quellen und Gründe für die Bewertung einzusehen und eigenständig zu überprüfen.

### Quantitative Ergebnisse

#### Stichprobe

Der Datensatz für die Analyse wurde vor einem Team vorgefiltert, eine zusätzliche Filterung oder Ausschlusskriterien nach Datenerhebung war nicht erforderlich. Es wurden N = 176 Teilnehmenden in die folgenden Analyse berrücksichtigt Die Stichprobe verteilte sich nahezu gleichmäßig: 89 Personen bearbeiteten die Aufgabe mit einer empfehlenden KI-Variante, während 87 Teilnehmende mit einer evaluativen Variante arbeiteten. Alle Teilnehmenden durchliefen eine Phase ohne und eine Phase mit KI-Unterstützung. Das Alter wurde metrisch erhoben. Das Durchschnittsalter betrug M = 25,9 (Mdn = 22, SD = 10,6). Eine obere Altersgrenze wurde nicht gesetzt, um eine möglichst diverse Stichprobe zu gewährleisten. Das Geschlecht wurde nominalskaliert erfasst (männlich, weiblich, divers). 90 Teilnehmende identifizierten sich als weiblich, 84 als männlich und 2 als non-binär. Auf die Frage nach der Vorerfahrung im Umgang mit Künstlicher Intelligenz (metrisch) stuften 9 Teilnehmende diese als sehr hoch ein, während zehn Personen angaben, über sehr geringe Vorerfahrung zu verfügen. Die Mehrheit von 85 Teilnehmenden bewertete ihre Vorerfahrung als mittelmäßig.

#### Deskriptive Statistik

Zur quantitativen Auswertung der Studie wurden zwei abhängige Variablen betrachtet: die subjektive mentale Belastung sowie das Vertrauen in das verwendete KI-System. Die mentale Belastung wurde mithilfe der DLR-Workload-Skala (@dlr119443) nach der Nutzung der jeweiligen KI-Anwendung erfasst. Die Erhebung erfolgte über eine visuelle Analogskala im Bereich von 0 bis 200 Punkten. Das Vertrauen in das System wurde anhand eines Einzelitems auf einer 5-Punkte-Likert-Skala gemessen (1 = sehr geringes Vertrauen, 5 = sehr hohes Vertrauen) nach @Mandsen_Gregor.

@tbl-belastung zeigt die deskriptiven Statistiken beider Variablen. Die mentale Belastung weist bei *N* = 176 einen Mittelwert von *M* = 105.90 (SD = 22.63) auf, bei einem Wertebereich von 44.38 bis 178.13. Dies deutet auf eine mittlere bis leicht erhöhte Beanspruchung hin. Das Vertrauen in das KI-System lag im Mittel bei *M* = 3.35 (SD = 0.93) und spiegelt somit eine eher neutrale bis tendenziell positive Haltung gegenüber der KI-Anwendung wider. Zur differenzierten Betrachtung der mentalen Belastung nach Interaktionstyp wurde zusätzlich eine Gruppierung nach KI-Typ vorgenommen (evaluativ vs. empfehlend). Dies wurde in @tbl-belastung zusammengefasst.

```{r}
#| label: setup
#| echo: false
#| message: false
#| warning: false

# Pakete laden
library(dplyr)
library(tidyr)
library(psych)
library(knitr)
library(kableExtra)
library(ggplot2)

# Daten einlesen
data <- read.csv("data_combined.csv", stringsAsFactors = FALSE)

# Items zur Belastung nach KI-Anwendung
ki_items <- grep("^ki_dlr_wat_", names(data), value = TRUE)

# Mittelwert berechnen (Belastung nach KI-Nutzung)
data$DLR_KI <- rowMeans(data[, ki_items], na.rm = TRUE)

# Gruppierungsvariable erstellen anhand vorhandener Werte
data$group <- NA
data$group[!is.na(data$workload_mean_E)] <- "Evaluativ"
data$group[!is.na(data$workload_mean_R)] <- "Empfehlend"

# Falls 'group' NA ist, und DLR_KI-Wert vorhanden, trotzdem mitnehmen
data_grouped <- data %>%
  filter(!is.na(group) & !is.na(DLR_KI))

# Deskriptive Statistik nach Gruppen
desc_stats_grouped <- data_grouped %>%
  group_by(group) %>%
  summarise(
    n = sum(!is.na(DLR_KI)),
    mean = mean(DLR_KI, na.rm = TRUE),
    median = median(DLR_KI, na.rm = TRUE),
    sd = sd(DLR_KI, na.rm = TRUE),
    min = min(DLR_KI, na.rm = TRUE),
    max = max(DLR_KI, na.rm = TRUE),
    .groups = "drop"
  )

#| label: tbl-belastung
#| tbl-cap: "Deskriptive Statistik der mentalen Belastung"
# Tabelle anzeigen
kable(desc_stats_grouped,
      caption = "Deskriptive Statistik der mentalen Belastung nach KI-Typ",
      booktabs = TRUE, digits = 2) %>%
  kable_styling()

```

```{r}
#| echo: false
#| message: false
#| warning: false

# Pakete laden
library(psych)
library(knitr)

# Daten laden
data <- read.csv("data_combined.csv", stringsAsFactors = FALSE)

# Items für die KI-Skala
ki_items <- grep("^ki_dlr_wat_", names(data), value = TRUE)
data$DLR_KI <- rowMeans(data[, ki_items], na.rm = TRUE)

# Vertrauen (invertiert)
data$Trust <- 7 - as.numeric(data$aiInformationDistrust)

# Cronbach's Alpha für mentale Belastung (KI)
alpha_ki <- psych::alpha(data[, ki_items], check.keys = TRUE)$total$raw_alpha


# Zusammenfassung 
summary_table <- data.frame(
  Variable = c("Mentale Belastung", "Vertrauen"),
  n = c(sum(!is.na(data$DLR_KI)), sum(!is.na(data$Trust))),
  mean = c(mean(data$DLR_KI, na.rm = TRUE), mean(data$Trust, na.rm = TRUE)),
  median = c(median(data$DLR_KI, na.rm = TRUE), median(data$Trust, na.rm = TRUE)),
  sd = c(sd(data$DLR_KI, na.rm = TRUE), sd(data$Trust, na.rm = TRUE)),
  min = c(min(data$DLR_KI, na.rm = TRUE), min(data$Trust, na.rm = TRUE)),
  max = c(max(data$DLR_KI, na.rm = TRUE), max(data$Trust, na.rm = TRUE)),
  alpha = c(round(alpha_ki, 3),"-")
)

#| label: tbl-belastung-vertrauen
#| tbl-cap: "Deskriptive Statistik für mentale Belastung und Vertrauen"

# Tabelle 
kable(summary_table, caption = "Deskriptive Statistik für mentale Belastung und Vertrauen", digits = 3)

```

#### Inferenzstatistik

Die durchschnittliche mentale Belastung unterschied sich nicht signifikant zwischen Teilnehmenden in der Bedingung „Empfehlend“ (M = 104,85, SD = 20,31) und der Bedingung „Evaluativ“ (M = 106,97, SD = 20,87), *t*(173,63) = -0,62, *p* = .536. Die Effektstärke entspricht nach Cohen (1988) einem kleinen Effekt. Dies deutet darauf hin, dass es keinen bedeutsamen Unterschied in der empfundenen mentalen Belastung zwischen den beiden KI-Typen gibt. Dies ist im Dot-and-Whisker-Plot @fig-belastung-plot veranschaulicht.

```{r}
#| echo: false
#| message: false
#| warning: false


# Unabhängiger t-Test (Welch-Test) für mentale Belastung
t_test_result <- t.test(DLR_KI ~ group,
                        data = data_grouped,
                        var.equal = FALSE)

# Daten für Plot vorbereiten
plot_data <- data_grouped %>%
  group_by(group) %>%
  summarise(
    mean = mean(DLR_KI, na.rm = TRUE),
    sd = sd(DLR_KI, na.rm = TRUE),
    n = n(),
    se = sd / sqrt(n),
    ci_lower = mean - qt(0.975, df = n - 1) * se,
    ci_upper = mean + qt(0.975, df = n - 1) * se,
    .groups = "drop"
  )

#| label: fig-belastung-plot
#| fig-cap: "Mentale Belastung nach KI-Typ"

# Dot-and-Whisker-Plot 
ggplot(plot_data, aes(x = group, y = mean)) +
  geom_point(size = 4, color = "#2C3E50") +
  geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0.1, color = "#2C3E50") + scale_y_continuous(limits = c(95, 115)) +
  labs(
    title = "Abbildung: Mentale Belastung nach KI-Typ",
    x = "KI-Typ",
    y = "Mentale Belastung (0–200)"
  ) +
  theme_minimal(base_size = 14)

```

Zudem wurde eine Korrelationsanalyse nach Pearson durchgeführt, um den Zusammenhang zwischen der subjektiv empfundenen mentalen Belastung und dem Vertrauen in das KI-System zu untersuchen. Die Analyse ergab eine signifikante negative Korrelation (r(174) = -0.23, p \< .002), was darauf hinweist, dass eine höhere empfundene kognitive Belastung mit einem tendenziell niedrigeren Vertrauen in das System einhergeht. Diese Beziehung wird in @fig-korrelation-belastung-vertrauen, dem Scatter-Plot mit Regressionslinie, grafisch dargestellt. Die Punktwolke zeigt eine leichte negative Tendenz, unterstützt durch die eingefügte Regressionslinie.

```{r}
#| echo: false
#| message: false
#| warning: false

#| label: fig-korrelation-belastung-vertrauen
#| fig-cap: "Zusammenhang: mentaler Belastung und Vertrauen"
# Scatter-Plot
ggplot(data, aes(x = DLR_KI, y = Trust)) +
  geom_point(color = "#0072B2", alpha = 0.7, size = 2) +
  geom_smooth(method = "lm", se = FALSE, color = "#D55E00") +
  labs(
    title = "Zusammenhang: mentale Belastung (DLR) und Vertrauen",
    x = "Mentale Belastung (DLR-Skala, mit KI)",
    y = "Vertrauen in das KI-System"
  ) +
  theme_minimal(base_size = 14)

# Korrelations-Test
cor_test <- cor.test(data$DLR_KI, data$Trust, method = "pearson")
```

Zusammenfassend lässt sich festhalten, dass sich die beiden getesteten KI-Systeme in ihrer Auswirkung auf die mentale Belastung nicht signifikant voneinander unterschieden. Beide Varianten führten zu vergleichbaren Belastungswerten, was darauf hinweist, dass der eingesetzte KI-Typ – evaluativ oder empfehlend – keinen entscheidenden Einfluss auf das subjektive Belastungsempfinden hatte. Allerdings zeigte sich ein relevanter Zusammenhang zwischen der empfundenen mentalen Belastung und dem Vertrauen in das System: Teilnehmende, die das System als stärker belastend wahrnahmen, berichteten tendenziell ein geringeres Vertrauen in die KI. Diese Ergebnisse sind insbesondere für die nutzerzentrierte Gestaltung von KI-Anwendungen bedeutsam, da sie nahelegen, dass eine wahrgenommene kognitive Entlastung das Vertrauen der Nutzenden in ein KI-System fördern kann.

### Diskussion

## Code of Conduct {.unnumbered}

Als Arbeitsgruppe verpflichten wir uns einem gemeinsamen Verhaltenskodex, der den Anforderungen wisschenschaftlicher Forschung und respektvollen Umgang entspricht. Dieser bildet die Grundlage für die Zusammenarbeit und beinhaltet folgende Punkte:

Wir begegenen einander offen und respektvoll. Konstruktives Feedback wird wertgeschätzend geäußert, aufgenommen und besprochen. Dabei sind unterschiedliche Perspektiven und Meinungen willkommen und werden als zur Zusammenarbeit gehörend betrachtet. Entsprechend wird sich im Konfliktfall gemeinsam bemüht wird, eine zufriedenstellende Lösung zu finden. Die Mitglieder werden als gleichberechtig angesehen und behandelt.

Es wird eine ausgewogene Aufteilung der Arbeitslast angestrebt, die die Stärken und Schwächen der einzelnen Mitgleider berücksichtigt. Folglich verpflichten wir uns zu einer offenen und direkten Kommunikation. Im Falle möglicher Verzögerungen, Probleme oder unerwarteter Auslastungen wird frühzeitig kommuniziert und sich gegenseitig unterstützt.

Wir verpflichten uns der Einhaltung wissenschaftlicher Standards, mit besonderer Umsicht gegenüber erhobener, personenbezogener Daten und der Wahrung ihrer Vertraulichkeit. Ebenso wird streng auf sorgfältigen Recherche und korrekte Zitation geachtet. Die verantwortungsvolle Nutzung von AI Tools erfolgt transparent mit Beschreibung und Kennzeichnung der Nutzung. So wurde @openai2025chatgpt genutzt, um die Formulierungen zu präzisieren, Code zu überprüfen und die Rechtschreibung zu kontrollieren.

## Literaturverzeichnis {.unnumbered}

## Anhang 1 - Rekrutierungstext {.unnumbered}

**Online-Studie zur Erkennung von Falschinformationen – Teilnehmende gesucht!**

Wir führen im Rahmen eines Forschungsmoduls eine **Online-Umfrage** durch (Dauer: ca. **60 Minuten**). In der Studie wird untersuchen, wie verschiedene KI-gestützte Systeme Menschen dabei unterstützen können, Falschinformationen zu erkennen.

G**esucht werden Teilnehmende, die...**

\- mindestens **18 Jahre alt** sind,

\- **nicht** an der Veranstaltung **SMNF** teilnehmen,

\- **Social Media zumindest gelegentlich nutzen**,

\- **Deutsch** sprechen und verstehen,

\- Zugriff auf ein **Tablet, Laptop oder PC** haben,

\- einen **modernen Browser** nutzen (z.B. Chrome, Firefox oder Safari).

**Wichtig:** Alle erhobenen Daten sind **vollständig anonym** und **nicht auf Sie rückführbar**.

Interesse? Hier geht's direkt zur Studie:

https://dsslab.hciuse.sh/study/pilot?groupId=gr-a2

Danke für Ihre Unterstützung!
