
@article{amri_afcc_2024,
	title = {Afcc: automatic fact-checkers’ consensus and credibility assessment for fake news detection},
	volume = {16},
	issn = {2511-2104, 2511-2112},
	shorttitle = {Afcc},
	url = {https://link.springer.com/10.1007/s41870-024-01956-1},
	doi = {10.1007/s41870-024-01956-1},
	language = {en},
	number = {8},
	urldate = {2025-05-02},
	journal = {International Journal of Information Technology},
	author = {Amri, Sabrine and Aïmeur, Esma},
	month = dec,
	year = {2024},
	pages = {4733--4748},
	file = {PDF:files/50/Amri und Aïmeur - 2024 - Afcc automatic fact-checkers’ consensus and credibility assessment for fake news detection.pdf:application/pdf},
}

@inproceedings{shu_defend_2019,
	address = {Anchorage AK USA},
	title = {{dEFEND}: {Explainable} {Fake} {News} {Detection}},
	isbn = {978-1-4503-6201-6},
	shorttitle = {{dEFEND}},
	url = {https://dl.acm.org/doi/10.1145/3292500.3330935},
	doi = {10.1145/3292500.3330935},
	abstract = {In recent years, to mitigate the problem of fake news, computational detection of fake news has been studied, producing some promising early results. While important, however, we argue that a critical missing piece of the study be the explainability of such detection, i.e., why a particular piece of news is detected as fake. In this paper, therefore, we study the explainable detection of fake news. We develop a sentence-comment co-attention sub-network to exploit both news contents and user comments to jointly capture explainable top-k check-worthy sentences and user comments for fake news detection. We conduct extensive experiments on realworld datasets and demonstrate that the proposed method not only significantly outperforms 7 state-of-the-art fake news detection methods by at least 5.33\% in F1-score, but also (concurrently) identifies top-k user comments that explain why a news piece is fake, better than baselines by 28.2\% in NDCG and 30.7\% in Precision.},
	language = {en},
	urldate = {2025-05-02},
	booktitle = {Proceedings of the 25th {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} \& {Data} {Mining}},
	publisher = {ACM},
	author = {Shu, Kai and Cui, Limeng and Wang, Suhang and Lee, Dongwon and Liu, Huan},
	month = jul,
	year = {2019},
	pages = {395--405},
	file = {PDF:files/51/Shu et al. - 2019 - dEFEND Explainable Fake News Detection.pdf:application/pdf},
}

@article{jwa_exbake_2019,
	title = {{exBAKE}: {Automatic} {Fake} {News} {Detection} {Model} {Based} on {Bidirectional} {Encoder} {Representations} from {Transformers} ({BERT})},
	volume = {9},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2076-3417},
	shorttitle = {{exBAKE}},
	url = {https://www.mdpi.com/2076-3417/9/19/4062},
	doi = {10.3390/app9194062},
	abstract = {News currently spreads rapidly through the internet. Because fake news stories are designed to attract readers, they tend to spread faster. For most readers, detecting fake news can be challenging and such readers usually end up believing that the fake news story is fact. Because fake news can be socially problematic, a model that automatically detects such fake news is required. In this paper, we focus on data-driven automatic fake news detection methods. We first apply the Bidirectional Encoder Representations from Transformers model (BERT) model to detect fake news by analyzing the relationship between the headline and the body text of news. To further improve performance, additional news data are gathered and used to pre-train this model. We determine that the deep-contextualizing nature of BERT is best suited for this task and improves the 0.14 F-score over older state-of-the-art models.},
	language = {en},
	number = {19},
	urldate = {2025-05-02},
	journal = {Applied Sciences},
	author = {Jwa, Heejung and Oh, Dongsuk and Park, Kinam and Kang, Jang Mook and Lim, Heuiseok},
	month = jan,
	year = {2019},
	note = {Number: 19
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {deep learning, fake information, fake news, fake news challenge, fake news classification, fake news detect},
	pages = {4062},
	file = {Full Text PDF:files/68/Jwa et al. - 2019 - exBAKE Automatic Fake News Detection Model Based on Bidirectional Encoder Representations from Tran.pdf:application/pdf},
}

@inproceedings{reis_explainable_2019,
	address = {New York, NY, USA},
	series = {{WebSci} '19},
	title = {Explainable {Machine} {Learning} for {Fake} {News} {Detection}},
	isbn = {978-1-4503-6202-3},
	url = {https://doi.org/10.1145/3292522.3326027},
	doi = {10.1145/3292522.3326027},
	abstract = {Recently, there have been many research efforts aiming to understand fake news phenomena and to identify typical patterns and features of fake news. Yet, the real discriminating power of these features is still unknown: some are more general, but others perform well only with specific data. In this work, we conduct a highly exploratory investigation that produced hundreds of thousands of models from a large and diverse set of features. These models are unbiased in the sense that their features are randomly chosen from the pool of available features. While the vast majority of models are ineffective, we were able to produce a number of models that yield highly accurate decisions, thus effectively separating fake news from actual stories. Specifically, we focused our analysis on models that rank a randomly chosen fake news story higher than a randomly chosen fact with more than 0.85 probability. For these models we found a strong link between features and model predictions, showing that some features are clearly tailored for detecting certain types of fake news, thus evidencing that different combinations of features cover a specific region of the fake news space. Finally, we present an explanation of factors contributing to model decisions, thus promoting civic reasoning by complementing our ability to evaluate digital content and reach warranted conclusions.},
	urldate = {2025-05-02},
	booktitle = {Proceedings of the 10th {ACM} {Conference} on {Web} {Science}},
	publisher = {Association for Computing Machinery},
	author = {Reis, Julio C. S. and Correia, André and Murai, Fabrício and Veloso, Adriano and Benevenuto, Fabrício},
	month = jun,
	year = {2019},
	pages = {17--26},
}

@article{kaliyar_fakebert_2021,
	title = {{FakeBERT}: {Fake} news detection in social media with a {BERT}-based deep learning approach},
	volume = {80},
	issn = {1573-7721},
	shorttitle = {{FakeBERT}},
	url = {https://doi.org/10.1007/s11042-020-10183-2},
	doi = {10.1007/s11042-020-10183-2},
	abstract = {In the modern era of computing, the news ecosystem has transformed from old traditional print media to social media outlets. Social media platforms allow us to consume news much faster, with less restricted editing results in the spread of fake news at an incredible pace and scale. In recent researches, many useful methods for fake news detection employ sequential neural networks to encode news content and social context-level information where the text sequence was analyzed in a unidirectional way. Therefore, a bidirectional training approach is a priority for modelling the relevant information of fake news that is capable of improving the classification performance with the ability to capture semantic and long-distance dependencies in sentences. In this paper, we propose a BERT-based (Bidirectional Encoder Representations from Transformers) deep learning approach (FakeBERT) by combining different parallel blocks of the single-layer deep Convolutional Neural Network (CNN) having different kernel sizes and filters with the BERT. Such a combination is useful to handle ambiguity, which is the greatest challenge to natural language understanding. Classification results demonstrate that our proposed model (FakeBERT) outperforms the existing models with an accuracy of 98.90\%.},
	language = {en},
	number = {8},
	urldate = {2025-05-02},
	journal = {Multimedia Tools and Applications},
	author = {Kaliyar, Rohit Kumar and Goswami, Anurag and Narang, Pratik},
	month = mar,
	year = {2021},
	keywords = {Artificial Intelligence, BERT, Deep learning, Fake news, Neural network, Social media},
	pages = {11765--11788},
	file = {Full Text PDF:files/71/Kaliyar et al. - 2021 - FakeBERT Fake news detection in social media with a BERT-based deep learning approach.pdf:application/pdf},
}

@article{szczepanski_new_2021,
	title = {New explainability method for {BERT}-based model in fake news detection},
	volume = {11},
	issn = {2045-2322},
	doi = {10.1038/s41598-021-03100-6},
	abstract = {The ubiquity of social media and their deep integration in the contemporary society has granted new ways to interact, exchange information, form groups, or earn money-all on a scale never seen before. Those possibilities paired with the widespread popularity contribute to the level of impact that social media display. Unfortunately, the benefits brought by them come at a cost. Social Media can be employed by various entities to spread disinformation-so called 'Fake News', either to make a profit or influence the behaviour of the society. To reduce the impact and spread of Fake News, a diverse array of countermeasures were devised. These include linguistic-based approaches, which often utilise Natural Language Processing (NLP) and Deep Learning (DL). However, as the latest advancements in the Artificial Intelligence (AI) domain show, the model's high performance is no longer enough. The explainability of the system's decision is equally crucial in real-life scenarios. Therefore, the objective of this paper is to present a novel explainability approach in BERT-based fake news detectors. This approach does not require extensive changes to the system and can be attached as an extension for operating detectors. For this purposes, two Explainable Artificial Intelligence (xAI) techniques, Local Interpretable Model-Agnostic Explanations (LIME) and Anchors, will be used and evaluated on fake news data, i.e., short pieces of text forming tweets or headlines. This focus of this paper is on the explainability approach for fake news detectors, as the detectors themselves were part of previous works of the authors.},
	language = {eng},
	number = {1},
	journal = {Scientific Reports},
	author = {Szczepański, Mateusz and Pawlicki, Marek and Kozik, Rafał and Choraś, Michał},
	month = dec,
	year = {2021},
	pmid = {34880354},
	pmcid = {PMC8655070},
	pages = {23705},
	file = {Volltext:files/78/Szczepański et al. - 2021 - New explainability method for BERT-based model in fake news detection.pdf:application/pdf},
}


@misc{openai2025chatgpt,
  author = {{OpenAI}},
  title = {{ChatGPT (Mar 2024 version)}},
  year  = {2025},
  howpublished = {\url{https://chat.openai.com/chat}},
  note = {[Large language model]}
}

